{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Tu44HsqWDWor"},"outputs":[],"source":["try:\n","  from google.colab import drive\n","  IN_COLAB=True\n","except:\n","  IN_COLAB=False\n","\n","if IN_COLAB:\n","  print(\"We're running Colab\")\n","  \n","  # Mount the Google Drive at mount\n","  mount='/content/drive'\n","  print(\"Colab: mounting Google drive on \", mount)\n","\n","  drive.mount(mount)\n","\n","  # Switch to the directory on the Google Drive that you want to use\n","  import os\n","  drive_root = mount + \"/My Drive/Colab Notebooks/ML-for-IC-Die-Images\"\n","  \n","  # Create drive_root if it doesn't exist\n","  create_drive_root = True\n","  if create_drive_root:\n","    print(\"\\nColab: making sure \", drive_root, \" exists.\")\n","    os.makedirs(drive_root, exist_ok=True)\n","  \n","  # Change to the directory\n","  print(\"\\nColab: Changing directory to \", drive_root)\n","  %cd $drive_root\n","  !pwd\n","\n","  # !pip install -r requirements.txt\n","  # !sudo apt-get autoremove\n","\n","\n","  from IPython.display import JSON\n","  from google.colab import output\n","  from subprocess import getoutput\n","  \n","  # @title jQuery Terminal's [Features](https://terminal.jcubic.pl/)\n","\n","  def shell(command):\n","    if command.startswith('cd'):\n","      path = command.strip().split(maxsplit=1)[1]\n","      os.chdir(path)\n","      return JSON([''])\n","    return JSON([getoutput(command)])\n","  output.register_callback('shell', shell)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14959,"status":"ok","timestamp":1680074954678,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"3b7NPR3H9NVN","outputId":"01e1d653-3673-414c-d826-f596a4dce752"},"outputs":[],"source":["if IN_COLAB:\n","    !pip install cupy-cuda112 tensorflow-addons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xaSwrEmAnbkX"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'more_itertools'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m division\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmore_itertools\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'more_itertools'"]}],"source":["# %%\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import more_itertools\n","import sys\n","import cv2\n","import os\n","import time\n","from matplotlib import style\n","#style.use('classic')\n","from numpy import genfromtxt, asarray, savez_compressed, load\n","from sklearn.model_selection import train_test_split\n","import PIL\n","from PIL import Image \n","from io import StringIO\n","# import memory_profiler\n","import numpy as np\n","import cupy\n","import matplotlib.pyplot as plt\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import glob\n","import time\n","#style.use('classic')\n","from joblib import Parallel, delayed\n","from numpy import genfromtxt\n","from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n","from sklearn.model_selection import train_test_split\n","from scipy.signal import resample\n","from io import StringIO\n","import os\n","import shutil\n","#plt.style.use('ggplot')\n","#matplotlib.use( 'tkagg' )\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.preprocessing import MinMaxScaler, QuantileTransformer, RobustScaler, StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","import pylab as pl\n","import seaborn as sns\n","sns.set_style(\"ticks\",{'axes.grid' : True})\n","from pathlib import Path\n","from collections.abc import Iterable\n","import math\n","\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.layers import Conv3D,Activation,Conv2D,Cropping2D, ConvLSTM2D, MaxPooling2D, MaxPooling3D, BatchNormalization, Flatten, Input, Dense, GRU, Embedding, LSTM, SimpleRNN, Dropout, Bidirectional, TimeDistributed\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n","from tensorflow.keras.utils import plot_model, to_categorical, Sequence, normalize\n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import tensorflow_addons as tfa\n","from tensorflow.python.ops import math_ops, control_flow_ops\n","from tensorflow.python.framework import constant_op\n","\n","\n","if IN_COLAB:\n","  from google.colab import drive\n","  from tensorflow.keras.optimizers.legacy import RMSprop,Adam,SGD,Adadelta,Adagrad,Adamax\n","  from tqdm.notebook import tqdm_notebook\n","else:\n","  from tensorflow.keras.optimizers import RMSprop,Adam,SGD,Adadelta,Adagrad,Adamax\n","  from tqdm.autonotebook import tqdm\n","\n","\n","from tensorflow.python.ops.numpy_ops import np_config\n","np_config.enable_numpy_behavior()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3322,"status":"ok","timestamp":1680074963517,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"kYmXzg1FnbkY","outputId":"f9fbbb5b-231c-4b54-9565-9b12acf4112d"},"outputs":[],"source":["from tensorflow.python.platform import build_info as tf_build_info\n","import tensorflow.python.platform.build_info as build\n","from tensorflow.compat.v1.keras.backend import set_session\n","\n","try:\n","  # tf.debugging.experimental.enable_dump_debug_info('.', tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n","  # tf.debugging.set_log_device_placement(True)\n","  from tensorflow.python.client import device_lib\n","\n","  device_name = tf.test.gpu_device_name()\n","  if device_name != '/device:GPU:0':\n","    raise SystemError('GPU device not found')\n","  print('Found GPU at: {}'.format(device_name))\n","\n","  config = tf.compat.v1.ConfigProto()\n","  config.gpu_options.allow_growth = True\n","  config.gpu_options.per_process_gpu_memory_fraction = 0.1\n","  try:\n","    tf.compat.v1.InteractiveSession.close()\n","  except Exception as error:\n","    print(\"Error trying to delete session\")\n","    print(error) \n","  sess = tf.compat.v1.InteractiveSession(config=config)\n","  set_session(sess)\n","  print(device_lib.list_local_devices())\n","  gpus = tf.config.experimental.list_physical_devices('GPU')\n","  for gpu in gpus:\n","    try:\n","    \n","      tf.config.experimental.set_memory_growth(gpu, True)\n","      # Restrict TensorFlow to only use the first GPU\n","      tf.config.set_visible_devices(gpus[0], 'GPU')\n","      logical_gpus = tf.config.list_logical_devices('GPU')\n","      print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n","    except RuntimeError as e:\n","      # Visible devices must be set before GPUs have been initialized\n","      print(e)\n","\n","except Exception as error:\n","    print(\"Error trying to configure computing device.\")\n","    print(error)\n","\n","print(\"TensorFlow verison: \",tf.__version__)\n","print(\"CUDA verison: \", build.build_info['cuda_version'])\n","print(\"CUDNN verison: \", build.build_info['cudnn_version'])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"m8bB9ucqnbka"},"source":["### Set Tensorflow-GPU precision \n","Mixed precision is the use of both 16-bit and 32-bit floating-point types in a model during training to make it run faster and use less memory. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1680074963518,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"2lk8Y11Enbkc","outputId":"0a54735b-6deb-464c-e1d6-89f79ca68a37"},"outputs":[],"source":["# tf.keras.backend.floatx()\n","# tf.keras.backend.set_floatx('float16')\n","# tf.keras.backend.set_floatx('float32')\n","# policy = tf.keras.mixed_precision.Policy('mixed_float16')\n","# tf.keras.mixed_precision.set_global_policy(policy)\n","tf.keras.backend.floatx()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_QUaBNmKC-cu"},"outputs":[],"source":["# Change as you wish\n","if IN_COLAB:\n","  DATA_FOLDER = './data'\n","  TRAIN_FOLDER = './data/Train'\n","  VALIDATION_FOLDER = './data/Validation'\n","  IMAGE_INPUT_FOLDER = './data/Image_Input'\n","  IMAGE_OUTPUT_FOLDER = './data/Image_Output'\n","else:\n","  DATA_FOLDER = './../data'\n","  TRAIN_FOLDER = './../data/Train'\n","  VALIDATION_FOLDER = './../data/Validation'\n","  IMAGE_INPUT_FOLDER = './../data/Image_Input'\n","  IMAGE_OUTPUT_FOLDER = './../data/Image_Output'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sBGuGJPOnbkd"},"outputs":[],"source":["# Set the paths to your annotated image folders\n","input_image_path = os.path.join(IMAGE_INPUT_FOLDER)\n","output_image_path = os.path.join(IMAGE_OUTPUT_FOLDER)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2896,"status":"ok","timestamp":1680074966382,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"oDsGXIkhC-cu","outputId":"d95a57a2-e4f2-48c5-fae9-bb9c5a4cfb5a"},"outputs":[],"source":["# Get the list of image and label file paths\n","input_filenames = sorted(glob.glob(os.path.join(input_image_path,'*.jpg')))[:]\n","output_filenames = sorted(glob.glob(os.path.join(output_image_path,'*.jpg')))[:]\n","\n","len(input_filenames), len(output_filenames)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1680074966382,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"UootvLM8z3jn","outputId":"f649039a-6b44-4f5c-a917-3bc6ec465da6"},"outputs":[],"source":["for idx, inp_outp in enumerate(zip(input_filenames[:], output_filenames[:])):\n","  print(idx, inp_outp)"]},{"cell_type":"markdown","metadata":{"id":"2HF6_MfP7pke"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1680074966383,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"uFve0OxT9-zy","outputId":"dcd19cbd-26f7-4584-d1db-6d561d7d15aa"},"outputs":[],"source":["if len(input_filenames[:])==len(output_filenames[:]):\n","  print('Number of files in Input and Output folders are equal')\n","else:\n","  min_file_length = min([len(input_filenames[:]),len(output_filenames[:])])\n","  print(f'Uneven number images in Input and Output folders! \\nSelecting minimum possible number of images: {min_file_length}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1680074966384,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"QAzrmcfUnbkd","outputId":"c1677b2b-a1bd-4c13-aafe-738bd96becba"},"outputs":[],"source":["min_file_length=-1\n","if IN_COLAB:\n","  check_ims = [in_name.split('/')[3]==out_name.split('/')[3] for in_name,out_name in zip(input_filenames[:min_file_length], output_filenames[:min_file_length])]\n","else:\n","  check_ims = [in_name.split('\\\\')[1]==out_name.split('\\\\')[1] for in_name,out_name in zip(input_filenames[:min_file_length], output_filenames[:min_file_length])]\n","any(not x for x in check_ims) #Check if at least one image names is not corresponding "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":484,"status":"ok","timestamp":1680074966855,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"lm0A4DKtnbke","outputId":"20226fbc-597a-44c7-a0e5-ef3d45d4a67e"},"outputs":[],"source":["test_size = 0.05  #Specify test percentage\n","\n","# Split the image and label file paths into training and validation sets\n","train_image_paths, validation_image_paths, train_label_paths, validation_label_paths = train_test_split(input_filenames[:], output_filenames[:], test_size=test_size, shuffle=True)\n","\n","# Create the training and validation folders\n","train_folder_path = os.path.join(TRAIN_FOLDER)\n","validation_folder_path = os.path.join(VALIDATION_FOLDER)\n","\n","os.makedirs(os.path.join(train_folder_path, 'Input_Image'), exist_ok=True)\n","os.makedirs(os.path.join(train_folder_path, 'Output_Image'), exist_ok=True)\n","os.makedirs(os.path.join(validation_folder_path, 'Input_Image'), exist_ok=True)\n","os.makedirs(os.path.join(validation_folder_path, 'Output_Image'), exist_ok=True)\n","\n","'''\n","# Copy the training images and labels to the training folder\n","for image_path, label_path in zip(train_image_paths, train_label_paths):\n","    image_name = os.path.basename(image_path)\n","    label_name = os.path.basename(label_path)\n","    shutil.copy(image_path, os.path.join(train_folder_path, 'Input_Image', image_name))\n","    shutil.copy(label_path, os.path.join(train_folder_path, 'Output_Image',label_name))\n","\n","# Copy the validation images and labels to the validation folder\n","for image_path, label_path in zip(validation_image_paths, validation_label_paths):\n","    image_name = os.path.basename(image_path)\n","    label_name = os.path.basename(label_path)\n","    shutil.copy(image_path, os.path.join(validation_folder_path, 'Input_Image', image_name))\n","    shutil.copy(label_path, os.path.join(validation_folder_path, 'Output_Image', label_name))\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffrPUKG5nbkf"},"outputs":[],"source":["class CustomDataGenerator(Sequence):\n","    def __init__(self, input_paths, output_paths, batch_size, input_shape, num_classes=5, plot=False):\n","        self.input_paths = input_paths\n","        self.output_paths = output_paths\n","        self.batch_size = batch_size\n","        self.input_shape = input_shape\n","        self.plot = plot\n","        self.num_classes = num_classes\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.input_paths) / float(self.batch_size)))\n","\n","    def __getitem__(self, idx):\n","        input_batch_paths = self.input_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        output_batch_paths = self.output_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n","\n","        input_images = cupy.asnumpy(list(map(self.image_dataloader, input_batch_paths))).astype(np.float32)\n","        output_images = cupy.asnumpy(list(map(self.image_dataloader, output_batch_paths))).astype(np.float32)\n","        segmentation_mask = cupy.asnumpy(list(map(self.mask_generator, [output_image - input_image for input_image, output_image in zip(input_images,output_images)]))).astype(np.float32)\n","        return input_images, segmentation_mask #.reshape(-1,height*width,channels)\n","        \n","\n","    def image_dataloader(self, image_path):\n","        # Load the input image\n","        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","        # image = image.reshape(image.shape[0],image.shape[1],image.shape[2])\n","        image = image.reshape(image.shape[0],image.shape[1],1)\n","        # Resize the image with padding\n","        image = cv2.resize(image, self.input_shape, interpolation=cv2.INTER_AREA)\n","        # image = resize_with_padding(image, self.input_shape)\n","        # Add an alpha channel to the input image\n","        # image = cv2.cvtColor(image, cv2.COLOR_RGB2RGBA)\n","        if self.plot:\n","            plt.figure()\n","            plt.imshow(image)\n","            plt.title(f'Path: {image_path}')\n","            plt.show()\n","        return image.reshape(image.shape[0],image.shape[1],1)/255.\n","    \n","    def mask_generator(self, image):\n","        blurred_image = skimage.filters.gaussian(image, sigma=1.0)\n","        t = skimage.filters.threshold_otsu(blurred_image)\n","        binary_mask = blurred_image > t\n","        # selection = output_validation_batch[i]/255.\n","        # selection[~binary_mask] = 0\n","        return binary_mask\n","        \n","    def resize_with_padding(self, image, target_size):\n","        \"\"\"\n","        Resizes an image with padding and maintains aspect ratio while keeping the background transparent.\n","        :param image: input image as a numpy array\n","        :param target_size: a tuple (width, height) representing the target size of the output image\n","        :return: the resized image as a numpy array\n","        \"\"\"\n","        h, w = image.shape[:2]\n","        target_w, target_h = target_size\n","\n","        # Calculate the scale factor and the new dimensions\n","        scale = min(target_w / w, target_h / h)\n","        new_w = int(w * scale)\n","        new_h = int(h * scale)\n","\n","        # Resize the image\n","        image_resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n","\n","        # Create a transparent background\n","        background = np.zeros((target_h, target_w, 4), dtype=np.uint8)\n","        background[:, :, 3] = 0  # set alpha channel to zero\n","\n","        # Calculate the coordinates to paste the resized image\n","        x = int((target_w - new_w) / 2)\n","        y = int((target_h - new_h) / 2)\n","\n","        # Paste the resized image onto the transparent background\n","        background[y:y+new_h, x:x+new_w, :3] = image_resized\n","        background[y:y+new_h, x:x+new_w, 3] = 255  # set alpha channel to 255 (fully opaque)\n","\n","        return image_resized"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qHiyynqfnbkg"},"outputs":[],"source":["height, width, channels = 512, 512, 1   # Choose maximum possible image size in order not to compromise quality\n","batch_size = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19349,"status":"ok","timestamp":1680074986175,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"geV88M-snbkg","outputId":"da2d0732-cd28-4bf3-814a-902631906e68"},"outputs":[],"source":["train_generator = CustomDataGenerator(train_image_paths, train_label_paths, batch_size, \n","                                      input_shape=(height, width), num_classes=5, plot=False)\n","\n","validation_generator = CustomDataGenerator(validation_image_paths, validation_label_paths, batch_size, \n","                                           input_shape=(height, width), num_classes=5, plot=False)\n","\n","input_train_batch, output_train_batch=next(iter(train_generator))\n","\n","print('x_train shape: ', input_train_batch.shape, 'x_train dtype:', input_train_batch.dtype)\n","print('y_train shape: ', output_train_batch.shape, 'y_train dtype:', output_train_batch.dtype)\n","# print('y_train shape: ', output_train_batch[0].shape, 'y_train dtype:', output_train_batch[0].dtype)\n","# print('y_train shape: ', output_train_batch[1].shape, 'y_train dtype:', output_train_batch[1].dtype)\n","\n","input_validation_batch, output_validation_batch=next(iter(validation_generator))\n","\n","print('x_val shape: ', input_validation_batch.shape, 'x_val dtype:', input_validation_batch.dtype)  \n","print('y_val shape: ', output_validation_batch.shape, 'y_val dtype:', output_validation_batch.dtype)\n","# print('y_val shape: ', output_validation_batch[0].shape, 'y_val dtype:', output_validation_batch[0].dtype)\n","# print('y_val shape: ', output_validation_batch[1].shape, 'y_val dtype:', output_validation_batch[1].dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(3):\n","    \n","    blurred_image = skimage.filters.gaussian(output_validation_batch[i]/255., sigma=1.0)\n","    t = skimage.filters.threshold_otsu(blurred_image)\n","    binary_mask = blurred_image > t\n","    selection = output_validation_batch[i]/255.\n","    selection[~binary_mask] = 0\n","\n","\n","\n","    import skimage\n","    # blur the image to denoise\n","    blurred_image = skimage.filters.gaussian(output_validation_batch[i]/255., sigma=1.0)\n","\n","    # show the histogram of the blurred image\n","    histogram, bin_edges = np.histogram(blurred_image, bins=256, range=(0.0, 1.0))\n","    fig, ax = plt.subplots()\n","    plt.plot(bin_edges[0:-1], histogram)\n","    plt.title(\"Graylevel histogram\")\n","    plt.xlabel(\"gray value\")\n","    plt.ylabel(\"pixel count\")\n","    plt.xlim(0, 1.0)\n","\n","    # perform automatic thresholding\n","    t = skimage.filters.threshold_otsu(blurred_image)\n","    print(\"Found automatic threshold t = {}.\".format(t))\n","\n","    # create a binary mask with the threshold found by Otsu's method\n","    binary_mask = blurred_image > t\n","\n","    fig, ax = plt.subplots()\n","    plt.imshow(binary_mask, cmap=\"gray\")\n","    plt.show()\n","\n","    # apply the binary mask to select the foreground\n","    selection = output_validation_batch[i]/255.\n","    selection[~binary_mask] = 0\n","\n","    fig, ax = plt.subplots()\n","    plt.imshow(selection)\n","    plt.show()\n","\n","    fig, ax = plt.subplots()\n","    plt.imshow(output_validation_batch[i]/255.)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":826},"executionInfo":{"elapsed":2904,"status":"ok","timestamp":1680074989052,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"nuL4NwzKSQRX","outputId":"17948b13-5412-490a-e4a9-68eb006c90da"},"outputs":[],"source":["plt.imshow(input_validation_batch[0], cmap='gray')\n","plt.title('Original Image')\n","plt.show()\n","plt.imshow(output_validation_batch[0], cmap='gray')\n","plt.title('Annotation Mask')\n","plt.show()\n","masked_image = input_validation_batch[0][~output_validation_batch[0].astype('bool').squeeze( axis=-1)]\n","plt.imshow(masked_image, cmap='gray')\n","plt.title('Manual Annotation with Mask')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"JwzenbowW2OF"},"source":["Build CONV2D Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsFLPftODnSM"},"outputs":[],"source":["def build_annotator_model(input_shape, output_channels, dropout_rate=0.0):\n","    \"\"\"\n","    Builds a TensorFlow model that takes original images as input and produces annotated images as output.\n","    \n","    Args:\n","        input_shape: The shape of the input image (e.g. (256, 256, 3) for a 256x256 RGB image).\n","        output_channels: The number of output channels (i.e. the number of annotation colors).\n","    \n","    Returns:\n","        The TensorFlow model.\n","    \"\"\"\n","    # Define the input layer\n","    inputs = tf.keras.layers.Input(shape=input_shape)\n","    \n","    # Encoder\n","    conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='gelu')(inputs)\n","    conv1 = tf.keras.layers.Dropout(dropout_rate)(conv1)\n","    # conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='gelu')(conv1)\n","    bn1 = tf.keras.layers.BatchNormalization(name='BN1')(conv1)\n","\n","    conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='gelu')(bn1)\n","    conv2 = tf.keras.layers.Dropout(dropout_rate)(conv2)\n","    # conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='gelu')(conv2)\n","    bn2 = tf.keras.layers.BatchNormalization(name='BN2')(conv2)\n","    \n","    conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same', activation='gelu')(bn2)\n","    conv3 = tf.keras.layers.Dropout(dropout_rate)(conv3)\n","    # conv3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same', activation='gelu')(conv3)\n","    bn3 = tf.keras.layers.BatchNormalization(name='BN3')(conv3)\n","\n","    conv4 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same', activation='gelu')(bn3)\n","    conv4 = tf.keras.layers.Dropout(dropout_rate)(conv4)\n","    # conv4 = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same', activation='gelu')(conv4)\n","    bn4 = tf.keras.layers.BatchNormalization(name='BN4')(conv4)\n","\n","    conv5 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', activation='gelu')(bn4)\n","    conv5 = tf.keras.layers.Dropout(dropout_rate)(conv5)\n","    # conv5 = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, padding='same', activation='gelu')(conv5)\n","    bn5 = tf.keras.layers.BatchNormalization(name='BN5')(conv5)\n","\n","    \n","    # Decoder\n","    deconv1 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size=3, strides=2, padding='same', activation='gelu')(bn5)\n","    deconv1 = tf.keras.layers.Dropout(dropout_rate)(deconv1)\n","    #deconv1 = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size=3, strides=2, padding='same', activation='gelu')(deconv1)\n","    bn6 = tf.keras.layers.BatchNormalization(name='BN6')(deconv1)\n","\n","    skip1 = tf.keras.layers.concatenate([bn4, bn6])\n","\n","    deconv2 = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=3, strides=2, padding='same', activation='gelu')(skip1)\n","    deconv2 = tf.keras.layers.Dropout(dropout_rate)(deconv2)\n","    # deconv2 = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=3, strides=2, padding='same', activation='gelu')(deconv2)\n","    bn7 = tf.keras.layers.BatchNormalization(name='BN7')(deconv2)\n","\n","    skip2 = tf.keras.layers.concatenate([bn3, bn7])\n","\n","    deconv3 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same', activation='gelu')(skip2)\n","    deconv3 = tf.keras.layers.Dropout(dropout_rate)(deconv3)\n","    # deconv3 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same', activation='gelu')(deconv3)\n","    bn8 = tf.keras.layers.BatchNormalization(name='BN8')(deconv3)\n","\n","    skip3 = tf.keras.layers.concatenate([bn2, bn8])\n","\n","    deconv4 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='gelu')(skip3)\n","    deconv4 = tf.keras.layers.Dropout(dropout_rate)(deconv4)\n","    # deconv4 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='gelu')(deconv4)\n","\n","    bn9 = tf.keras.layers.BatchNormalization(name='BN9')(deconv4)\n","    skip4 = tf.keras.layers.concatenate([bn1, bn9])\n","\n","    deconv5 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='gelu')(skip4)\n","    deconv5 = tf.keras.layers.Dropout(dropout_rate)(deconv5)\n","    # deconv5 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='gelu')(deconv5)\n","    bn10 = tf.keras.layers.BatchNormalization(name='BN10')(deconv5)\n","    \n","    segmentation_mask = tf.keras.layers.Conv2DTranspose(filters=output_channels, kernel_size=3, strides=1, padding='same', activation='linear')(bn10)\n","    \n","    # annotated_pred = tf.keras.layers.Multiply()([inputs, segmentation_mask])\n","    annotated_pred = tf.keras.layers.Add()([inputs, segmentation_mask])\n","    annotated_pred = tf.keras.layers.Multiply()([annotated_pred,(tf.ones_like(input_validation_batch[0].shape)*255.) ])\n","    annotated_pred = tf.keras.layers.Activation('relu')(annotated_pred)\n","\n","    # outputs = tf.keras.layers.Flatten()(annotated_pred)\n","    # outputs = tf.keras.layers.Dense(input_shape[0], activation='softmax')(outputs)\n","    # outputs = tf.keras.layers.Reshape(target_shape=(input_shape[0],input_shape[1],channels))(outputs)\n","    \n","    # Create the model\n","    model = tf.keras.Model(inputs=inputs, outputs=annotated_pred, name='Annotation_model')\n","    \n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10260,"status":"ok","timestamp":1680074999300,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"LHLcscGmIciA","outputId":"f718b3c0-fc34-4f94-c330-1efdcea0afb4"},"outputs":[],"source":["try:\n","  del model\n","except:\n","  pass\n","\n","# Define the input and output shapes\n","input_shape = (height, width, channels)\n","output_channels = channels\n","\n","# if model:  del model\n","# Build the model\n","model = build_annotator_model(input_shape, output_channels)\n","\n","# Create Optimizer.\n","# Define the parameters for the schedule\n","initial_learning_rate = 1e-2\n","decay_steps = 1200\n","first_decay_steps = 1200\n","\n","# Create the schedule\n","optimizer = Adam(learning_rate=initial_learning_rate, amsgrad=True)\n","moving_avg_Adam = tfa.optimizers.MovingAverage(optimizer)\n","stocastic_avg_Adam = tfa.optimizers.SWA(optimizer) \n","\n","# Compile the model with an appropriate loss function and optimizer\n","# model.compile(loss=PixelWiseCrossEntropy(), optimizer=optimizer, metrics=['acc'], run_eagerly=True)\n","model.compile(loss='mse', optimizer=stocastic_avg_Adam, metrics=['mse','acc'], run_eagerly=True)\n","\n","\n","with tf.device('/device:GPU:0'):\n","  _ = model.predict(validation_generator, steps=1, verbose=1)\n","  _ = model.evaluate(train_generator, verbose=1)  \n","  # _ = model.fit(train_generator, epochs=1, verbose=1)  \n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"hXA3pfpzqjBk"},"source":["Visualize Annotation Model Graph"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_model(model, show_shapes=True, to_file=os.path.join(DATA_FOLDER, f'model/Annotation_model.png'), show_layer_names=True, rankdir='TB', expand_nested=True, dpi=50)"]},{"cell_type":"markdown","metadata":{"id":"JjQOFXrZnbki"},"source":["## Implement Callback Functions\n","\n","During training we want to save checkpoints and log the progress to TensorBoard so we create the appropriate callbacks for Keras.\n","This is the callback for writing checkpoints during training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfaBpa7znbkj"},"outputs":[],"source":["from tensorflow.python.framework.test_util import run_functions_eagerly\n","save_format = 'h5'\n","path_checkpoint = os.path.join(DATA_FOLDER, f'model/Annotation_model.{save_format}')\n","callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n","                                      monitor='val_acc',\n","                                      verbose=1,\n","                                      save_weights_only=True,\n","                                      restore_best_weights=True,\n","                                      save_best_only=True, \n","                                      run_functions_eagerly=True,\n","                                      save_format=save_format)\n","\n","path_checkpoint_MA = os.path.join(DATA_FOLDER, f'model/Annotation_model_MA.{save_format}')\n","\n","path_checkpoint_SWA = os.path.join(DATA_FOLDER, f'model/Annotation_model_SWA.{save_format}')\n","\n","callback_MA = tfa.callbacks.AverageModelCheckpoint(filepath=path_checkpoint_MA, \n","                                                    monitor='val_acc',\n","                                                    update_weights=True,\n","                                                    save_weights_only=True,\n","                                                    run_functions_eagerly=True, \n","                                                    save_format=save_format)\n","\n","callback_SWA = tfa.callbacks.AverageModelCheckpoint(filepath=path_checkpoint_SWA,\n","                                                    monitor='val_acc',\n","                                                    update_weights=True,\n","                                                    save_weights_only=True,\n","                                                    run_functions_eagerly=True,\n","                                                    save_format=save_format)"]},{"cell_type":"markdown","metadata":{"id":"MT8g2IsFnbkk"},"source":["This is the callback for stopping the optimization when performance worsens on the validation-set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A5Tv6qUDnbkk"},"outputs":[],"source":["callback_early_stopping = EarlyStopping(  monitor=\"val_acc\",\n","                                          # min_delta=0,\n","                                          patience=400,\n","                                          verbose=1,\n","                                          mode=\"auto\",\n","                                          # baseline=None,\n","                                          restore_best_weights=True )"]},{"cell_type":"markdown","metadata":{"id":"3TZYZOU3nbkl"},"source":["This is the callback for writing the TensorBoard log during training."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2286,"status":"ok","timestamp":1680075003476,"user":{"displayName":"Desmond Hammond","userId":"17685451081689258891"},"user_tz":-120},"id":"SC1X6JHknbkl","outputId":"e00a1f52-3e26-41f5-bf70-8dbdec810cc7"},"outputs":[],"source":["dirpaths = [Path(os.path.join(DATA_FOLDER, r'model//TensorBoard/'))]\n","\n","for dirpath in dirpaths:\n","    if dirpath.exists() and dirpath.is_dir():\n","        try:        \n","            shutil.rmtree(dirpath, ignore_errors=True)\n","            os.chmod(dirpath, 0o777)\n","            os.rmdir(dirpath)\n","            os.removedirs(dirpath)\n","            print(\"Directory '%s' has been removed successfully\", dirpath)\n","        except OSError as error:\n","            print(error)\n","            print(\"Directory '%s' can not be removed\", dirpath)\n","\n","logdir = os.path.join(DATA_FOLDER, r'model//TensorBoard/')\n","# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","callback_tensorboard = TensorBoard(log_dir=logdir,\n","                                   histogram_freq=1,\n","                                   write_graph=True,\n","                                   profile_batch = '500,520')"]},{"cell_type":"markdown","metadata":{"id":"ExwTKXh3nbkl"},"source":["This callback reduces the learning-rate for the optimizer if the validation-loss has not improved since the last epoch (as indicated by `patience=100`). The learning-rate will be reduced by multiplying it with the given factor. We set a start learning-rate of 1e-2 above, so multiplying it by 0.95 gives a learning-rate of 9.5e-3. We don't want the learning-rate to go any lower 1e-5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCgfLMBLnbkl"},"outputs":[],"source":["callback_reduce_lr = ReduceLROnPlateau(monitor='val_acc',\n","                                       factor=0.99,\n","                                       min_lr=1e-5,\n","                                       patience=5,\n","                                       verbose=1)    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhq9pxsmnbkl"},"outputs":[],"source":["class CosineDecayRestarts(tf.keras.callbacks.Callback):\n","    def __init__(self, initial_learning_rate, first_decay_steps, alpha=0.0, t_mul=2.0, m_mul=1.0):\n","        super(CosineDecayRestarts, self).__init__()\n","        self.initial_learning_rate = initial_learning_rate\n","        self.first_decay_steps = first_decay_steps\n","        self.alpha = alpha\n","        self.t_mul = t_mul\n","        self.m_mul = m_mul\n","        self.batch_step = 0\n","\n","    def on_train_batch_begin(self, step, logs=None):\n","        if not hasattr(self.model.optimizer, \"lr\"):\n","            raise ValueError('Optimizer must have a \"lr\" attribute.')\n","        # Get the current learning rate from model's optimizer.\n","        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n","        # Call schedule function to get the scheduled learning rate.\n","        scheduled_lr = self.schedule(self.batch_step, lr)\n","        # Set the value back to the optimizer before this epoch starts\n","        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n","        self.batch_step += 1\n","\n","    def schedule(self, step, lr):\n","        def compute_step(completed_fraction, geometric=False):\n","            \"\"\"Helper for `cond` operation.\"\"\"\n","            if geometric:\n","                i_restart = math_ops.floor(\n","                  math_ops.log(1.0 - completed_fraction * (1.0 - self.t_mul)) /\n","                  math_ops.log(self.t_mul))\n","\n","                sum_r = (1.0 - self.t_mul**i_restart) / (1.0 - self.t_mul)\n","                completed_fraction = (completed_fraction - sum_r) / self.t_mul**i_restart\n","\n","            else:\n","                i_restart = math_ops.floor(completed_fraction)\n","                completed_fraction -= i_restart\n","\n","            return i_restart, completed_fraction\n","\n","        completed_fraction = step / self.first_decay_steps\n","\n","        i_restart, completed_fraction = control_flow_ops.cond(\n","          math_ops.equal(self.t_mul, 1.0),\n","          lambda: compute_step(completed_fraction, geometric=False),\n","          lambda: compute_step(completed_fraction, geometric=True))\n","\n","        m_fac = self.m_mul**i_restart\n","        cosine_decayed = 0.5 * m_fac * (1.0 + math_ops.cos(\n","          constant_op.constant(math.pi) * completed_fraction))\n","        decayed = (1 - self.alpha) * cosine_decayed + self.alpha\n","\n","        return math_ops.multiply(self.initial_learning_rate, decayed)\n","\n","callback_cosine_decay_restarts = CosineDecayRestarts( initial_learning_rate,\n","                                                      first_decay_steps )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KbwlBGZVnbkm"},"outputs":[],"source":["callbacks = [callback_early_stopping,\n","             callback_checkpoint,\n","             callback_tensorboard,\n","             callback_cosine_decay_restarts,\n","             callback_SWA,\n","             callback_reduce_lr]\n","\n","# callbacks = list()"]},{"cell_type":"markdown","metadata":{"id":"55KUnBUNnbkm"},"source":["#### Load weights from last checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U8rq7zM4nbkm"},"outputs":[],"source":["def train_model(resume, epochs, initial_epoch, batch_size, model, savepath):\n","    with tf.device('/device:GPU:0'):\n","        print(model.summary())\n","        history=model.fit(train_generator, \n","                          steps_per_epoch=steps_per_epoch, \n","                          epochs=EPOCHS, \n","                          verbose=1, \n","                          callbacks=callbacks,\n","                          validation_data=validation_generator, \n","                          validation_steps=validation_steps, \n","                          #validation_freq=5,\n","                          #class_weight=None, \n","                          #max_queue_size=10, \n","                          #workers=8, \n","                          #use_multiprocessing=True,\n","                          shuffle=True, \n","                          initial_epoch=initial_epoch)\n","        \n","        model.load_weights(savepath)\n","        print(\"Checkpoint Loaded\")  \n","        model.evaluate(test_generator, steps=test_steps)\n","\n","    if resume:\n","        try:\n","            #del model\n","            model.load_weights(savepath, {\"CustomLoss\":CustomLoss()})\n","            #model = load_model(savepath, {\"CustomLoss\":CustomLoss()})\n","            print(\"Checkpoint Loaded\")  \n","        except Exception as error:\n","            print(\"Error trying to load checkpoint.\")\n","            print(error)\n","\n","    return history, model\n","    \n","with tf.device('/device:GPU:0'):\n","    def plot_train_history(history, title):\n","        loss = history.history['loss']\n","        accuracy = history.history['acc']\n","        mape = history.history['mape']\n","        mae = history.history['mae']\n","        val_acc = history.history['val_acc']\n","        val_accuracy = history.history['val_acc']\n","        val_mae = history.history['val_mae']\n","        val_mape = history.history['val_mape']\n","        epochs = range(len(loss))\n","        plt.figure(figsize=(30,5))\n","        plt.plot(epochs, loss, label='training_loss') \n","        plt.plot(epochs, val_acc, label='validation_loss')\n","        plt.show()\n","        plt.figure(figsize=(30,5))\n","        plt.plot(epochs, accuracy, label='training_accuracy') \n","        plt.plot(epochs, val_accuracy, label='validation_accuracy')\n","        plt.show()\n","        plt.figure(figsize=(30,5))\n","        plt.plot(epochs, mae, label='training_mae') \n","        plt.plot(epochs, val_mae, label='validation_mae')\n","        plt.show()\n","        plt.figure(figsize=(30,5))\n","        plt.plot(epochs, mape, label='training_mape') \n","        plt.plot(epochs, val_mape, label='validation_mape')\n","        plt.show()\n","        return"]},{"cell_type":"markdown","metadata":{"id":"cxk35XWmnbkm"},"source":["## Train Model"]},{"cell_type":"markdown","metadata":{"id":"w3Yyq29znbkn"},"source":["# Load the TensorBoard notebook extension\n","# %load_ext tensorboard\n","%reload_ext tensorboard\n","\n","%tensorboard --logdir './data/model/TensorBoard/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bk8o-yGQnbkn"},"outputs":[],"source":["EPOCHS = 100000\n","\n","train_steps = steps_per_epoch = len(train_image_paths)//batch_size\n","test_steps = validation_steps =  len(validation_image_paths)//batch_size\n","test_generator = validation_generator\n","\n","try:\n","  model.load_weights(os.path.join(DATA_FOLDER, f'model/Annotation_model.{save_format}'))\n","  model.save_weights(os.path.join(DATA_FOLDER, f'model/Annotation_model'), save_format=save_format)\n","  # model.set_weights(load_model(os.path.join(DATA_FOLDER, f'model/Annotation_model'), {\"CustomLoss\":CustomLoss()()}).get_weights())\n","  # model.save(os.path.join(DATA_FOLDER, f'model/Annotation_model'), save_format=save_format)\n","  # model = load_model(os.path.join(DATA_FOLDER, f'model/Annotation_model.{save_format}'), {\"CustomLoss\":CustomLoss()}, compile=True)\n","  print(\"Checkpoint Loaded\")\n","except Exception as error:\n","  print(\"Error trying to load checkpoint.\")\n","  print(error)\n","                     \n","history, model = train_model(resume=False, epochs=EPOCHS, initial_epoch=0, batch_size=batch_size, model=model, savepath=path_checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"GfBpgoUVnbko"},"source":["### Load Checkpoint\n","\n","Because we use early-stopping when training the model, it is possible that the model's performance has worsened on the test-set for several epochs before training was stopped. We therefore reload the last saved checkpoint, which should have the best performance on the test-set."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Jocf4vjNnbko"},"outputs":[],"source":["with tf.device('/device:GPU:0'):\n","    try:\n","        model.load_weights(os.path.join(DATA_FOLDER, f'model/Annotation_model.{save_format}'))\n","        model = load_model(os.path.join(DATA_FOLDER, f'model/Annotation_model'), {\"CustomLoss\":CustomLoss()})\n","        # model.set_weights(load_model(os.path.join(DATA_FOLDER, f'model/Annotation_model'), {\"CustomLoss\":CustomLoss()}).get_weights())\n","        print(\"Checkpoint Loaded\")\n","    except Exception as error:\n","        print(\"Error trying to load checkpoint.\")\n","        print(error)"]},{"cell_type":"markdown","metadata":{"id":"5lcYcUcbnbko"},"source":["## Performance on Test-Set\n","\n","We can now evaluate the model's performance on the test-set. This function expects a batch of data, but we will just use one long time-series for the test-set, so we just expand the array-dimensionality to create a batch with that one sequence."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AAbqSrPsnbko"},"outputs":[],"source":["with tf.device('/device:GPU:0'):\n","    model.evaluate(train_generator, steps=train_steps)\n","    model.evaluate(validation_generator, steps=validation_steps)\n","    model.evaluate(test_generator, steps=test_steps)"]},{"cell_type":"markdown","metadata":{"id":"AERG613OPMj2"},"source":["Predict on Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input_validation_batch.max()\n","annotated_pred.max()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mSTUpIOQTTzK"},"outputs":[],"source":["# Predict the annotation with model\n","annotated_pred = model.predict(input_validation_batch, steps=1)\n","\n","for idx in range(batch_size):\n","    plt.imshow(input_validation_batch[idx])\n","    plt.title('Original Image')\n","    plt.show()\n","    plt.imshow(output_validation_batch[idx])\n","    plt.title('True Annotation Mask')\n","    plt.show()\n","    plt.imshow(annotated_pred[idx])\n","    plt.title('Predicted Annotation Mask')\n","    plt.show()\n","    plt.imshow(input_validation_batch[idx] + output_validation_batch[idx])\n","    plt.title('True Annotated Image')\n","    plt.show()\n","    plt.imshow(input_validation_batch[idx] + annotated_pred[idx])\n","    plt.title('Manual Annotation with Predicted Mask')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"4fbfea1dd5a17f80dff8df3ba641602c59e31ce1a55b82aea18e6894ff3c71a7"}}},"nbformat":4,"nbformat_minor":0}
